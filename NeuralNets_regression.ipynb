{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from resources.arabic_preprocessing import Arabic_preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-ar-joy-train-1</td>\n",
       "      <td>Ù…Ù†Ø³Ù… ÙŠÙ‚ÙˆÙ„ Ù„ØµÙŠØ¯Ù„ÙŠ\\n\\nØ¹Ù†Ø¯Ùƒ Ø´Ø±ÙŠØ· Ø¨Ù†Ø§Ø¯ÙˆÙ„ØŸ\\nÙ‚Ø§Ù„Ù‡:Ù†Ø¹...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-ar-joy-train-2</td>\n",
       "      <td>Â· Ø¨ØªÙƒØ¨Ø±ÙŠÙ† ÙŠØ§Ù„Ù„ÙŠ Ù…Ù† Ø±Ø¶Ø§ Ø§Ù„Ø£ÙŠØ§Ù… Ø¬ÙŠØªÙŠ ÙŠÙˆÙ… Ù…ÙŠÙ„Ø§Ø¯Ùƒ ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-ar-joy-train-3</td>\n",
       "      <td>#Ù‡Ø¯ÙˆØ¡ #Ø¹Ù…Ø±Ùˆ Ø¯ÙŠØ§Ø¨ #Ù…Ø²Ø§Ø¬ â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-ar-joy-train-4</td>\n",
       "      <td>Ø³Ø¨Ø­Ø§Ù† Ø§Ù„Ù„Ù‡ #Ø±Ø¶Ù‰ Ø§Ù„ÙˆØ§Ù„Ø¯ÙŠÙ† Ù„Ù‡ Ø³Ø­Ø± Ø¹Ø¬ÙŠØ¨</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-ar-joy-train-5</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ±Ø¶Ù‰ Ø¹Ù„ÙŠÙƒ. \\nØ¨Ø¯Ù„ Ù…ØªÙ‚ÙˆÙ„ÙŠ: (Ø¹ÙŠØ¯ Ø³Ø¹ÙŠØ¯)ØŒ Ù‚ÙˆÙ„ÙŠ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 index                                              tweet  \\\n",
       "0  2018-ar-joy-train-1  Ù…Ù†Ø³Ù… ÙŠÙ‚ÙˆÙ„ Ù„ØµÙŠØ¯Ù„ÙŠ\\n\\nØ¹Ù†Ø¯Ùƒ Ø´Ø±ÙŠØ· Ø¨Ù†Ø§Ø¯ÙˆÙ„ØŸ\\nÙ‚Ø§Ù„Ù‡:Ù†Ø¹...   \n",
       "1  2018-ar-joy-train-2  Â· Ø¨ØªÙƒØ¨Ø±ÙŠÙ† ÙŠØ§Ù„Ù„ÙŠ Ù…Ù† Ø±Ø¶Ø§ Ø§Ù„Ø£ÙŠØ§Ù… Ø¬ÙŠØªÙŠ ÙŠÙˆÙ… Ù…ÙŠÙ„Ø§Ø¯Ùƒ ...   \n",
       "2  2018-ar-joy-train-3                  #Ù‡Ø¯ÙˆØ¡ #Ø¹Ù…Ø±Ùˆ Ø¯ÙŠØ§Ø¨ #Ù…Ø²Ø§Ø¬ â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸   \n",
       "3  2018-ar-joy-train-4               Ø³Ø¨Ø­Ø§Ù† Ø§Ù„Ù„Ù‡ #Ø±Ø¶Ù‰ Ø§Ù„ÙˆØ§Ù„Ø¯ÙŠÙ† Ù„Ù‡ Ø³Ø­Ø± Ø¹Ø¬ÙŠØ¨   \n",
       "4  2018-ar-joy-train-5  Ø§Ù„Ù„Ù‡ ÙŠØ±Ø¶Ù‰ Ø¹Ù„ÙŠÙƒ. \\nØ¨Ø¯Ù„ Ù…ØªÙ‚ÙˆÙ„ÙŠ: (Ø¹ÙŠØ¯ Ø³Ø¹ÙŠØ¯)ØŒ Ù‚ÙˆÙ„ÙŠ...   \n",
       "\n",
       "  emotion  score  \n",
       "0     joy  0.422  \n",
       "1     joy  0.565  \n",
       "2     joy  0.438  \n",
       "3     joy  0.375  \n",
       "4     joy  0.438  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=pd.read_csv('data/joy_train.csv',header=None, names=['index', 'tweet','emotion','score'])\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-ar-joy-train-1</td>\n",
       "      <td>Ù…Ù†Ø³Ù… Ù‚ÙˆÙ„ Ù„ØµÙŠØ¯Ù„ÙŠ Ø¹Ù†Ø¯ Ø´Ø±ÙŠØ· Ø¨Ù†Ø§Ø¯ÙˆÙ„ Ù‚Ø§Ù„Ù‡Ù†Ø¹Ù… Ù‚Ø§Ù„ Ø´Øº...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-ar-joy-train-2</td>\n",
       "      <td>Â· Ø¨ØªÙƒØ¨Ø± Ø§Ù„ÙŠ Ø±Ø¶Ø§ Ø§ÙŠÙ… Ø¬ÙŠØªÙŠ Ù…ÙŠÙ„Ø§Ø¯ ÙØ±Ø­ Ø¹Ù…Ø± Ù…Ùˆ Ø§Ø±ÙŠØ®...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-ar-joy-train-3</td>\n",
       "      <td>Ù‡Ø¯ÙˆØ¡ Ø¹Ù…Ø±Ùˆ Ø¯ÙŠØ§Ø¨ Ù…Ø²Ø§Ø¬ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-ar-joy-train-4</td>\n",
       "      <td>Ø§Ù„Ù‡ Ø±Ø¶ÙŠ ÙˆØ§Ù„Ø¯ Ø³Ø­Ø± Ø¹Ø¬ÙŠØ¨</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-ar-joy-train-5</td>\n",
       "      <td>Ø§Ù„Ù‡ Ø±Ø¶ÙŠ Ø¨Ø¯Ù„ Ù…ØªÙ‚ÙˆÙ„ÙŠ Ø¹ÙŠØ¯ Ø³Ø¹ÙŠØ¯ Ù‚ÙˆÙ„ÙŠ Ù‚Ø¯Ø§Ù… 6 Ù„ÙŠØ§Ù„ÙŠ ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 index                                              tweet  \\\n",
       "0  2018-ar-joy-train-1  Ù…Ù†Ø³Ù… Ù‚ÙˆÙ„ Ù„ØµÙŠØ¯Ù„ÙŠ Ø¹Ù†Ø¯ Ø´Ø±ÙŠØ· Ø¨Ù†Ø§Ø¯ÙˆÙ„ Ù‚Ø§Ù„Ù‡Ù†Ø¹Ù… Ù‚Ø§Ù„ Ø´Øº...   \n",
       "1  2018-ar-joy-train-2  Â· Ø¨ØªÙƒØ¨Ø± Ø§Ù„ÙŠ Ø±Ø¶Ø§ Ø§ÙŠÙ… Ø¬ÙŠØªÙŠ Ù…ÙŠÙ„Ø§Ø¯ ÙØ±Ø­ Ø¹Ù…Ø± Ù…Ùˆ Ø§Ø±ÙŠØ®...   \n",
       "2  2018-ar-joy-train-3       Ù‡Ø¯ÙˆØ¡ Ø¹Ù…Ø±Ùˆ Ø¯ÙŠØ§Ø¨ Ù…Ø²Ø§Ø¬ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸   \n",
       "3  2018-ar-joy-train-4                              Ø§Ù„Ù‡ Ø±Ø¶ÙŠ ÙˆØ§Ù„Ø¯ Ø³Ø­Ø± Ø¹Ø¬ÙŠØ¨   \n",
       "4  2018-ar-joy-train-5  Ø§Ù„Ù‡ Ø±Ø¶ÙŠ Ø¨Ø¯Ù„ Ù…ØªÙ‚ÙˆÙ„ÙŠ Ø¹ÙŠØ¯ Ø³Ø¹ÙŠØ¯ Ù‚ÙˆÙ„ÙŠ Ù‚Ø¯Ø§Ù… 6 Ù„ÙŠØ§Ù„ÙŠ ...   \n",
       "\n",
       "  emotion  score  \n",
       "0     joy  0.422  \n",
       "1     joy  0.565  \n",
       "2     joy  0.438  \n",
       "3     joy  0.375  \n",
       "4     joy  0.438  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = Arabic_preprocessing()\n",
    "sample['tweet']=sample['tweet'].apply(lambda x : prep.preprocess_arabic_text(x))\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3019\n"
     ]
    }
   ],
   "source": [
    "X = sample['tweet'].tolist()\n",
    "y_train = sample['score'].tolist()\n",
    "count_vect = CountVectorizer(lowercase=False, token_pattern=r'\\S+')\n",
    "count_vect = count_vect.fit(X)  # bag of words\n",
    "tfidf = TfidfTransformer()\n",
    "tfidf = tfidf.fit(count_vect.transform(X))\n",
    "X_train_count = count_vect.transform(X)\n",
    "X_train_tfidf = tfidf.transform(X_train_count.toarray())\n",
    "input_count = X_train_count.shape[1]\n",
    "print(input_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the model : Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(input_len, learning_rate=0.001):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4000, input_dim=input_len, activation='relu'))\n",
    "    model.add(Dense(2000, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    # Compile model\n",
    "    rmsprop = RMSprop(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=rmsprop, metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "**run either 'Without GridSearch' or 'Manual Grid Search', not both!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "224/600 [==========>...................] - ETA: 7s - loss: 7.9196 - mean_squared_error: 7.9196"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a7d13d1062c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#history = estimator.fit(X_train_count.toarray(), y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='mean_squared_error', patience=5)\n",
    "callbacks = [early_stop]\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=32, input_len=input_count)\n",
    "#history = estimator.fit(X_train_count.toarray(), y_train)\n",
    "history = estimator.fit(X_train_tfidf.toarray(), y_train, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='mean_squared_error', patience=5)\n",
    "callbacks = [early_stop]\n",
    "\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "models = []\n",
    "histories = []\n",
    "for lr in learning_rates:\n",
    "    # evaluate model with standardized dataset\n",
    "    estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=32, input_len=input_count, learning_rate=lr)\n",
    "    #history = estimator.fit(X_train_count.toarray(), y_train)\n",
    "    history = estimator.fit(X_train_tfidf.toarray(), y_train, callbacks=callbacks)\n",
    "    models.append(estimator)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sample=pd.read_csv('joy_test.csv',header=None, names=['index', 'tweet','emotion','score'])\n",
    "test_sample['tweet']=test_sample['tweet'].apply(lambda x : prep.preprocess_arabic_text(x))\n",
    "\n",
    "X_test = test_sample['tweet'].tolist()\n",
    "y_test = test_sample['score'].tolist()\n",
    "X_test_count = count_vect.transform(X_test)\n",
    "X_test_tfidf = tfidf.transform(X_test_count.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: R2 : 0.992522, RMSE : 0.000254\n",
      "Test: R2 : -0.039579, RMSE : 0.033070\n"
     ]
    }
   ],
   "source": [
    "y_pred = estimator.predict(X_test_tfidf.toarray())\n",
    "y_pred_train = estimator.predict(X_train_tfidf.toarray())\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train: R2 : {0:f}, RMSE : {1:f}\".format( r2_train, rmse_train ) )\n",
    "print( \"Test: R2 : {0:f}, RMSE : {1:f}\".format( r2, rmse ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8440000000000001  >>  0.64284  >>  [array(['Ø§Ø±Ø¨', 'Ø§Ù„Ù‡', 'Ø§ÙŠÙ…', 'Ø§ÙŠÙ…ÙŠ', 'Ø¬Ø¹Ù„', 'Ø¬Ù…Ù„', 'Ø­Ø¨', 'Ø®ÙŠØ±', 'Ø±ÙÙŠÙ‚',\n",
      "       'Ø²ÙØ§Ù', 'Ø³Ø¹Ø¯', 'Ø¹Ø±ÙˆØ³', 'ÙØ±Ø­', 'Ù„Ùƒ', 'Ù…ÙˆØ¹Ø¯', 'ÙŠØ§', 'ÙŠØªÙ…', 'ğŸ’'], \n",
      "      dtype='<U22')]\n",
      "0.563  >>  0.571871  >>  [array(['Ø³Ø§Ø¹Øª', 'Ø³Ø¹Ø§Ø¯', 'ÙÙŠÙ‡Ù…'], \n",
      "      dtype='<U22')]\n",
      "0.43799999999999994  >>  0.521823  >>  [array(['Ø§ÙˆÙ„', 'Ø­Ù‚ÙŠÙ‚', 'Ø®ÙŠØ±', 'Ø¯Ø¹Ù…', 'Ø±Ø¬Ø§Ù„', 'Ø²Ø¹Ø§Ù…', 'Ø´ÙƒØ±', 'Ø¹Ø±Ø³', 'ØºÙŠØ±',\n",
      "       'Ù‚Ø¯Ù…', 'Ù‚Ù„Ø¨', 'ÙƒØ¨ÙŠØ±', 'Ù„Ø¬Ù…ÙŠØ¹', 'Ù‡Ù„Ø§Ù„'], \n",
      "      dtype='<U22')]\n",
      "0.25  >>  0.588215  >>  [array(['Ø¨Ø³', 'ØªØ§Ù…', 'Ø­Ø¨', 'Ø­Ø²Ù†', 'Ø­ÙŠÙ†', 'Ø­ÙŠÙˆÙŠ', 'Ø´Ø¹ÙˆØ±', 'Ø·Ø§Ù‚', 'ÙˆÙ…Ùˆ'], \n",
      "      dtype='<U22')]\n",
      "0.359  >>  0.578135  >>  [array(['Ø¨Ø§Ù„ÙŠ', 'Ø­Ù„Ù…', 'Ø±Ø¨', 'Ø³Ù…Ø§', 'Ù…Ùˆ', 'ÙŠØ§'], \n",
      "      dtype='<U22')]\n",
      "0.703  >>  0.699126  >>  [array(['Ø§Ù†Ùˆ', 'Ø¨ØªØ­Ø¨', 'Ø¬Ùˆ', 'Ø³Ø¹Ø§Ø¯', 'Ø´Ø®Øµ', 'Ø¹Ø§Ù„Ù…', 'Ø¹ÙŠØ¯', 'ÙØ±Ø­'], \n",
      "      dtype='<U22')]\n",
      "0.75  >>  0.667876  >>  [array(['Ø¨ØªÙ‡Ø¬', 'Ø³Ø®Ø±', 'Ø´ØªØºÙ„', 'Ø·Ø¨ÙŠØ¹ÙŠ', 'Ø¹Ù„ÙŠ', 'ÙƒÙÙŠ', 'Ù…Ø¹Ø§ÙŠ', 'Ù…Ùˆ'], \n",
      "      dtype='<U22')]\n",
      "0.452  >>  0.314568  >>  [array(['Ø§Ø«Ø±', 'ØªØ´ÙˆÙŠÙ‚'], \n",
      "      dtype='<U22')]\n",
      "0.172  >>  0.479073  >>  [array(['Ø§Ø­ØªÙØ§Ù„', 'Ø§Ù„Ù‡', 'Ø¯Ù†ÙŠ', 'Ø³Ø§Ù…Ø­', 'ØµÙˆØª', 'Ø·Ù„Ø¹', 'ÙØ±Øµ', 'Ù„ÙƒÙ…'], \n",
      "      dtype='<U22')]\n",
      "0.609  >>  0.60821  >>  [array(['Ø§Ø¬Ø±', 'Ø§Ù„Ù‡', 'Ø§Ù‡Ù„', 'Ø¨Ø§Ø°', 'Ø±Ø­', 'ÙØ±Ø­ÙŠ', 'Ù‚Ø¨Ù„', 'Ù‚Ø¯Ø±ÙŠ', 'ÙƒÙ…Ø§'], \n",
      "      dtype='<U22')]\n",
      "0.547  >>  0.643778  >>  [array(['Ø¬Ø¨Øª', 'ÙØ±Ø­', 'ÙØ´Ø®'], \n",
      "      dtype='<U22')]\n",
      "0.297  >>  0.514646  >>  [array(['Ø¨Ø³', 'Ø®Ø¬Ù„', 'Ø·Ø±ÙŠÙ‚', 'Ù…Ø±Ø­Ø¨', 'Ù…ÙƒÙ†'], \n",
      "      dtype='<U22')]\n",
      "0.613  >>  0.622723  >>  [array(['Ø§Ø¨ØªØ³Ø§Ù…', 'Ø§Ø«Ø±', 'Ø¬Ù…ÙŠÙ„', 'Ø­ÙˆÙ„', 'Ø¯Ø¹', 'Ø¯ÙŠÙ†', 'Ø³Ø¹Ø§Ø¯', 'ØµØ­Ù‡', 'ØµØ¯Ù‚',\n",
      "       'ÙÙ‡ÙŠ', 'Ù‚Ù„Ø¨', 'Ù„Ùƒ', 'Ù„Ù…Ù†', 'Ù…Ù„Ø§Ù…Ø­', 'Ù…ÙˆØ³ÙŠÙ‚', 'ğŸƒ'], \n",
      "      dtype='<U22')]\n",
      "0.625  >>  0.602636  >>  [array(['5050', 'Ø§Ø¹Ù„', 'Ø¨Ù‡Ø¬', 'Ø¯Ù‡', 'Ø¹Ø¨Ù‚Ø±ÙŠ'], \n",
      "      dtype='<U22')]\n",
      "0.43799999999999994  >>  0.618942  >>  [array(['Ø§Ø®Ø±', 'Ø­ÙØ¸', 'Ø±Ø¨ÙŠ', 'Ø±Ø²Ù‚', 'Ø±Ø¶Ø§', 'Ø´Ù…Ø³', 'Ø¹ØªÙ…', 'Ø¹Ù…Ø±', 'ÙØ±Ø­',\n",
      "       'ÙØ³ÙŠ', 'Ù‚Ù„Ø¨', 'Ù„Ù‡Ù…', 'Ù„ÙŠÙ„'], \n",
      "      dtype='<U22')]\n",
      "0.547  >>  0.501676  >>  [array(['Ø§ØµÙˆ', 'Ø±Ø³ÙˆÙ…', 'Ø¶Ø­Ùƒ', 'Ù…ØªØ­Ø±Ùƒ'], \n",
      "      dtype='<U22')]\n",
      "0.344  >>  0.507934  >>  [array(['Ø§Ù‡Ù„', 'Ø¨Ù„Ø§', 'Ø¬Ø§Ù…Ø¹', 'Ø­Ø¯', 'Ø³ØªÙ…ØªØ¹', 'Ø³Ø®Ø±', 'Ø´Ø¨Ø¹'], \n",
      "      dtype='<U22')]\n",
      "0.828  >>  0.721661  >>  [array(['Ø§Ù„ÙŠ', 'Ø¨ØªØ­Ù„Ù…', 'Ø¨ØªÙ†Ø§Ù…', 'Ø¨ÙŠÙ‡', 'Ø­Ø¨', 'Ø®Ù„ÙŠ', 'Ø¯Ø§', 'Ø±Ø¶ÙŠ', 'Ø³Ø¹Ø§Ø¯',\n",
      "       'ØµØ­ÙŠ', 'Ø¹Ø§Ø¯', 'ÙØ±Ø­', 'Ù‡ØªÙ„Ø§Ù‚ÙŠ'], \n",
      "      dtype='<U22')]\n",
      "0.484  >>  0.609399  >>  [array(['Ø¬Ù…Ù„', 'Ø­ÙŠØ§', 'Ø³Ø­Ø§Ø¨', 'Ø¶ØºØ·', 'Ø¹Ø´Ø§', 'ğŸ˜…'], \n",
      "      dtype='<U22')]\n",
      "0.484  >>  0.640499  >>  [array(['Ø§Ø±Ø¨', 'Ø­Ø¨', 'Ø³Ø¹Ø§Ø¯', 'Ø³Ø¹Ø¯', 'Ù‚Ù„Ø¨', 'Ù‚Ù„Ø¨ÙŠ', 'Ù…Ø³Ø§Ø¡', 'ÙŠØ§', 'âš˜'], \n",
      "      dtype='<U22')]\n",
      "0.823  >>  0.652203  >>  [array(['Ø¯ÙŠ', 'Ø³Ø®Ø±', 'Ø´ÙˆÙŠ', 'Ø·Ù„Ø¹', 'Ø¹Ù†Ø¯', 'ÙØ±Ø­', 'ÙƒØ¨Ø±', 'ÙƒÙ…Ø§', 'Ù„Ø³Ù‡'], \n",
      "      dtype='<U22')]\n",
      "0.391  >>  0.475083  >>  [array(['Ø³Ø¹Ø¯', 'Ø´ÙƒØ±', 'Ø´ÙŠØ¡', 'Ù‡Ø¯Ø§'], \n",
      "      dtype='<U22')]\n"
     ]
    }
   ],
   "source": [
    "for i in range(22,44):\n",
    "    print(y_test[-i], ' >> ', y_pred[-i], ' >> ', count_vect.inverse_transform(X_test_count[-i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
