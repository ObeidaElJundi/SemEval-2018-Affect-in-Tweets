{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from resources.arabic_preprocessing import Arabic_preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-ar-joy-train-1</td>\n",
       "      <td>Ù…Ù†Ø³Ù… ÙŠÙ‚ÙˆÙ„ Ù„ØµÙŠØ¯Ù„ÙŠ\\n\\nØ¹Ù†Ø¯Ùƒ Ø´Ø±ÙŠØ· Ø¨Ù†Ø§Ø¯ÙˆÙ„ØŸ\\nÙ‚Ø§Ù„Ù‡:Ù†Ø¹...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-ar-joy-train-2</td>\n",
       "      <td>Â· Ø¨ØªÙƒØ¨Ø±ÙŠÙ† ÙŠØ§Ù„Ù„ÙŠ Ù…Ù† Ø±Ø¶Ø§ Ø§Ù„Ø£ÙŠØ§Ù… Ø¬ÙŠØªÙŠ ÙŠÙˆÙ… Ù…ÙŠÙ„Ø§Ø¯Ùƒ ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-ar-joy-train-3</td>\n",
       "      <td>#Ù‡Ø¯ÙˆØ¡ #Ø¹Ù…Ø±Ùˆ Ø¯ÙŠØ§Ø¨ #Ù…Ø²Ø§Ø¬ â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-ar-joy-train-4</td>\n",
       "      <td>Ø³Ø¨Ø­Ø§Ù† Ø§Ù„Ù„Ù‡ #Ø±Ø¶Ù‰ Ø§Ù„ÙˆØ§Ù„Ø¯ÙŠÙ† Ù„Ù‡ Ø³Ø­Ø± Ø¹Ø¬ÙŠØ¨</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-ar-joy-train-5</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ±Ø¶Ù‰ Ø¹Ù„ÙŠÙƒ. \\nØ¨Ø¯Ù„ Ù…ØªÙ‚ÙˆÙ„ÙŠ: (Ø¹ÙŠØ¯ Ø³Ø¹ÙŠØ¯)ØŒ Ù‚ÙˆÙ„ÙŠ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 index                                              tweet  \\\n",
       "0  2018-ar-joy-train-1  Ù…Ù†Ø³Ù… ÙŠÙ‚ÙˆÙ„ Ù„ØµÙŠØ¯Ù„ÙŠ\\n\\nØ¹Ù†Ø¯Ùƒ Ø´Ø±ÙŠØ· Ø¨Ù†Ø§Ø¯ÙˆÙ„ØŸ\\nÙ‚Ø§Ù„Ù‡:Ù†Ø¹...   \n",
       "1  2018-ar-joy-train-2  Â· Ø¨ØªÙƒØ¨Ø±ÙŠÙ† ÙŠØ§Ù„Ù„ÙŠ Ù…Ù† Ø±Ø¶Ø§ Ø§Ù„Ø£ÙŠØ§Ù… Ø¬ÙŠØªÙŠ ÙŠÙˆÙ… Ù…ÙŠÙ„Ø§Ø¯Ùƒ ...   \n",
       "2  2018-ar-joy-train-3                  #Ù‡Ø¯ÙˆØ¡ #Ø¹Ù…Ø±Ùˆ Ø¯ÙŠØ§Ø¨ #Ù…Ø²Ø§Ø¬ â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸   \n",
       "3  2018-ar-joy-train-4               Ø³Ø¨Ø­Ø§Ù† Ø§Ù„Ù„Ù‡ #Ø±Ø¶Ù‰ Ø§Ù„ÙˆØ§Ù„Ø¯ÙŠÙ† Ù„Ù‡ Ø³Ø­Ø± Ø¹Ø¬ÙŠØ¨   \n",
       "4  2018-ar-joy-train-5  Ø§Ù„Ù„Ù‡ ÙŠØ±Ø¶Ù‰ Ø¹Ù„ÙŠÙƒ. \\nØ¨Ø¯Ù„ Ù…ØªÙ‚ÙˆÙ„ÙŠ: (Ø¹ÙŠØ¯ Ø³Ø¹ÙŠØ¯)ØŒ Ù‚ÙˆÙ„ÙŠ...   \n",
       "\n",
       "  emotion  score  \n",
       "0     joy  0.422  \n",
       "1     joy  0.565  \n",
       "2     joy  0.438  \n",
       "3     joy  0.375  \n",
       "4     joy  0.438  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=pd.read_csv('data/joy_train.csv',header=None, names=['index', 'tweet','emotion','score'])\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet</th>\n",
       "      <th>emotion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-ar-joy-train-1</td>\n",
       "      <td>Ù…Ù†Ø³Ù… Ù‚ÙˆÙ„ Ù„ØµÙŠØ¯Ù„ÙŠ Ø¹Ù†Ø¯ Ø´Ø±ÙŠØ· Ø¨Ù†Ø§Ø¯ÙˆÙ„ Ù‚Ø§Ù„Ù‡Ù†Ø¹Ù… Ù‚Ø§Ù„ Ø´Øº...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-ar-joy-train-2</td>\n",
       "      <td>Â· Ø¨ØªÙƒØ¨Ø± Ø§Ù„ÙŠ Ø±Ø¶Ø§ Ø§ÙŠÙ… Ø¬ÙŠØªÙŠ Ù…ÙŠÙ„Ø§Ø¯ ÙØ±Ø­ Ø¹Ù…Ø± Ù…Ùˆ Ø§Ø±ÙŠØ®...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-ar-joy-train-3</td>\n",
       "      <td>Ù‡Ø¯ÙˆØ¡ Ø¹Ù…Ø±Ùˆ Ø¯ÙŠØ§Ø¨ Ù…Ø²Ø§Ø¬ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-ar-joy-train-4</td>\n",
       "      <td>Ø§Ù„Ù‡ Ø±Ø¶ÙŠ ÙˆØ§Ù„Ø¯ Ø³Ø­Ø± Ø¹Ø¬ÙŠØ¨</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-ar-joy-train-5</td>\n",
       "      <td>Ø§Ù„Ù‡ Ø±Ø¶ÙŠ Ø¨Ø¯Ù„ Ù…ØªÙ‚ÙˆÙ„ÙŠ Ø¹ÙŠØ¯ Ø³Ø¹ÙŠØ¯ Ù‚ÙˆÙ„ÙŠ Ù‚Ø¯Ø§Ù… 6 Ù„ÙŠØ§Ù„ÙŠ ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 index                                              tweet  \\\n",
       "0  2018-ar-joy-train-1  Ù…Ù†Ø³Ù… Ù‚ÙˆÙ„ Ù„ØµÙŠØ¯Ù„ÙŠ Ø¹Ù†Ø¯ Ø´Ø±ÙŠØ· Ø¨Ù†Ø§Ø¯ÙˆÙ„ Ù‚Ø§Ù„Ù‡Ù†Ø¹Ù… Ù‚Ø§Ù„ Ø´Øº...   \n",
       "1  2018-ar-joy-train-2  Â· Ø¨ØªÙƒØ¨Ø± Ø§Ù„ÙŠ Ø±Ø¶Ø§ Ø§ÙŠÙ… Ø¬ÙŠØªÙŠ Ù…ÙŠÙ„Ø§Ø¯ ÙØ±Ø­ Ø¹Ù…Ø± Ù…Ùˆ Ø§Ø±ÙŠØ®...   \n",
       "2  2018-ar-joy-train-3       Ù‡Ø¯ÙˆØ¡ Ø¹Ù…Ø±Ùˆ Ø¯ÙŠØ§Ø¨ Ù…Ø²Ø§Ø¬ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸ Ø­Ø¨ ï¸   \n",
       "3  2018-ar-joy-train-4                              Ø§Ù„Ù‡ Ø±Ø¶ÙŠ ÙˆØ§Ù„Ø¯ Ø³Ø­Ø± Ø¹Ø¬ÙŠØ¨   \n",
       "4  2018-ar-joy-train-5  Ø§Ù„Ù‡ Ø±Ø¶ÙŠ Ø¨Ø¯Ù„ Ù…ØªÙ‚ÙˆÙ„ÙŠ Ø¹ÙŠØ¯ Ø³Ø¹ÙŠØ¯ Ù‚ÙˆÙ„ÙŠ Ù‚Ø¯Ø§Ù… 6 Ù„ÙŠØ§Ù„ÙŠ ...   \n",
       "\n",
       "  emotion  score  \n",
       "0     joy  0.422  \n",
       "1     joy  0.565  \n",
       "2     joy  0.438  \n",
       "3     joy  0.375  \n",
       "4     joy  0.438  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep = Arabic_preprocessing()\n",
    "sample['tweet']=sample['tweet'].apply(lambda x : prep.preprocess_arabic_text(x))\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3019\n"
     ]
    }
   ],
   "source": [
    "X = sample['tweet'].tolist()\n",
    "y_train = sample['score'].tolist()\n",
    "count_vect = CountVectorizer(lowercase=False, token_pattern=r'\\S+')\n",
    "count_vect = count_vect.fit(X)  # bag of words\n",
    "tfidf = TfidfTransformer()\n",
    "tfidf = tfidf.fit(count_vect.transform(X))\n",
    "X_train_count = count_vect.transform(X)\n",
    "X_train_tfidf = tfidf.transform(X_train_count.toarray())\n",
    "input_count = X_train_count.shape[1]\n",
    "print(input_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the model : Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model(input_len, learning_rate=0.001):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4000, input_dim=input_len, activation='relu'))\n",
    "    model.add(Dense(2000, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    # Compile model\n",
    "    rmsprop = RMSprop(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=rmsprop, metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "**run either 'Without GridSearch' or 'Manual Grid Search', not both!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 10s - loss: 2.8037 - mean_squared_error: 2.8037    \n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 9s - loss: 0.0345 - mean_squared_error: 0.0345     \n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 9s - loss: 0.0222 - mean_squared_error: 0.0222     \n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 9s - loss: 0.0223 - mean_squared_error: 0.0223     \n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 9s - loss: 0.0205 - mean_squared_error: 0.0205     \n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 9s - loss: 0.0157 - mean_squared_error: 0.0157     \n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 9s - loss: 0.0143 - mean_squared_error: 0.0143     \n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 9s - loss: 0.0108 - mean_squared_error: 0.0108     \n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 9s - loss: 0.0088 - mean_squared_error: 0.0088     \n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 9s - loss: 0.0091 - mean_squared_error: 0.0091     \n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 9s - loss: 0.0070 - mean_squared_error: 0.0070     \n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 9s - loss: 0.0057 - mean_squared_error: 0.0057     \n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 9s - loss: 0.0046 - mean_squared_error: 0.0046     \n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 9s - loss: 0.0053 - mean_squared_error: 0.0053     \n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 9s - loss: 0.0036 - mean_squared_error: 0.0036     \n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 9s - loss: 0.0041 - mean_squared_error: 0.0041     \n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 9s - loss: 0.0031 - mean_squared_error: 0.0031     \n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 9s - loss: 0.0026 - mean_squared_error: 0.0026     \n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 9s - loss: 0.0031 - mean_squared_error: 0.0031     \n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 9s - loss: 0.0023 - mean_squared_error: 0.0023     \n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 9s - loss: 0.0021 - mean_squared_error: 0.0021     \n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 9s - loss: 0.0020 - mean_squared_error: 0.0020     \n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 9s - loss: 0.0022 - mean_squared_error: 0.0022     \n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 9s - loss: 0.0016 - mean_squared_error: 0.0016     \n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 9s - loss: 0.0017 - mean_squared_error: 0.0017     \n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 9s - loss: 0.0019 - mean_squared_error: 0.0019     \n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 9s - loss: 0.0015 - mean_squared_error: 0.0015     \n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 9s - loss: 0.0014 - mean_squared_error: 0.0014     \n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 9s - loss: 0.0014 - mean_squared_error: 0.0014     \n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 10s - loss: 0.0013 - mean_squared_error: 0.0013    \n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 9s - loss: 0.0011 - mean_squared_error: 0.0011     \n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 9s - loss: 0.0013 - mean_squared_error: 0.0013     \n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 9s - loss: 0.0015 - mean_squared_error: 0.0015     \n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 9s - loss: 0.0013 - mean_squared_error: 0.0013     \n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 9s - loss: 7.7716e-04 - mean_squared_error: 7.7716e-04     \n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 9s - loss: 0.0012 - mean_squared_error: 0.0012     \n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 9s - loss: 9.4539e-04 - mean_squared_error: 9.4539e-04     \n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 9s - loss: 0.0010 - mean_squared_error: 0.0010     \n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 9s - loss: 0.0010 - mean_squared_error: 0.0010           \n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 9s - loss: 7.6215e-04 - mean_squared_error: 7.6215e-04     \n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 9s - loss: 0.0010 - mean_squared_error: 0.0010           \n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 9s - loss: 0.0010 - mean_squared_error: 0.0010             \n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 9s - loss: 8.6433e-04 - mean_squared_error: 8.6433e-04     \n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 9s - loss: 7.6427e-04 - mean_squared_error: 7.6427e-04     \n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 9s - loss: 5.0547e-04 - mean_squared_error: 5.0547e-04     \n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 9s - loss: 7.3554e-04 - mean_squared_error: 7.3554e-04     \n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 9s - loss: 7.4176e-04 - mean_squared_error: 7.4176e-04     \n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 10s - loss: 0.0011 - mean_squared_error: 0.0011      \n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 10s - loss: 6.6426e-04 - mean_squared_error: 6.6426e-04    \n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 9s - loss: 6.1878e-04 - mean_squared_error: 6.1878e-04     \n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 9s - loss: 7.3734e-04 - mean_squared_error: 7.3734e-04     \n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='mean_squared_error', patience=5)\n",
    "callbacks = [early_stop]\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=32, input_len=input_count)\n",
    "#history = estimator.fit(X_train_count.toarray(), y_train)\n",
    "history = estimator.fit(X_train_tfidf.toarray(), y_train, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='mean_squared_error', patience=5)\n",
    "callbacks = [early_stop]\n",
    "\n",
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "models = []\n",
    "histories = []\n",
    "for lr in learning_rates:\n",
    "    # evaluate model with standardized dataset\n",
    "    estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=32, input_len=input_count, learning_rate=lr)\n",
    "    #history = estimator.fit(X_train_count.toarray(), y_train)\n",
    "    history = estimator.fit(X_train_tfidf.toarray(), y_train, callbacks=callbacks)\n",
    "    models.append(estimator)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sample=pd.read_csv('joy_test.csv',header=None, names=['index', 'tweet','emotion','score'])\n",
    "test_sample['tweet']=test_sample['tweet'].apply(lambda x : prep.preprocess_arabic_text(x))\n",
    "\n",
    "X_test = test_sample['tweet'].tolist()\n",
    "y_test = test_sample['score'].tolist()\n",
    "X_test_count = count_vect.transform(X_test)\n",
    "X_test_tfidf = tfidf.transform(X_test_count.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: R2 : 0.992522, RMSE : 0.000254\n",
      "Test: R2 : -0.039579, RMSE : 0.033070\n"
     ]
    }
   ],
   "source": [
    "y_pred = estimator.predict(X_test_tfidf.toarray())\n",
    "y_pred_train = estimator.predict(X_train_tfidf.toarray())\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Train: R2 : {0:f}, RMSE : {1:f}\".format( r2_train, rmse_train ) )\n",
    "print( \"Test: R2 : {0:f}, RMSE : {1:f}\".format( r2, rmse ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8440000000000001  >>  0.64284  >>  [array(['Ø§Ø±Ø¨', 'Ø§Ù„Ù‡', 'Ø§ÙŠÙ…', 'Ø§ÙŠÙ…ÙŠ', 'Ø¬Ø¹Ù„', 'Ø¬Ù…Ù„', 'Ø­Ø¨', 'Ø®ÙŠØ±', 'Ø±ÙÙŠÙ‚',\n",
      "       'Ø²ÙØ§Ù', 'Ø³Ø¹Ø¯', 'Ø¹Ø±ÙˆØ³', 'ÙØ±Ø­', 'Ù„Ùƒ', 'Ù…ÙˆØ¹Ø¯', 'ÙŠØ§', 'ÙŠØªÙ…', 'ğŸ’'], \n",
      "      dtype='<U22')]\n",
      "0.563  >>  0.571871  >>  [array(['Ø³Ø§Ø¹Øª', 'Ø³Ø¹Ø§Ø¯', 'ÙÙŠÙ‡Ù…'], \n",
      "      dtype='<U22')]\n",
      "0.43799999999999994  >>  0.521823  >>  [array(['Ø§ÙˆÙ„', 'Ø­Ù‚ÙŠÙ‚', 'Ø®ÙŠØ±', 'Ø¯Ø¹Ù…', 'Ø±Ø¬Ø§Ù„', 'Ø²Ø¹Ø§Ù…', 'Ø´ÙƒØ±', 'Ø¹Ø±Ø³', 'ØºÙŠØ±',\n",
      "       'Ù‚Ø¯Ù…', 'Ù‚Ù„Ø¨', 'ÙƒØ¨ÙŠØ±', 'Ù„Ø¬Ù…ÙŠØ¹', 'Ù‡Ù„Ø§Ù„'], \n",
      "      dtype='<U22')]\n",
      "0.25  >>  0.588215  >>  [array(['Ø¨Ø³', 'ØªØ§Ù…', 'Ø­Ø¨', 'Ø­Ø²Ù†', 'Ø­ÙŠÙ†', 'Ø­ÙŠÙˆÙŠ', 'Ø´Ø¹ÙˆØ±', 'Ø·Ø§Ù‚', 'ÙˆÙ…Ùˆ'], \n",
      "      dtype='<U22')]\n",
      "0.359  >>  0.578135  >>  [array(['Ø¨Ø§Ù„ÙŠ', 'Ø­Ù„Ù…', 'Ø±Ø¨', 'Ø³Ù…Ø§', 'Ù…Ùˆ', 'ÙŠØ§'], \n",
      "      dtype='<U22')]\n",
      "0.703  >>  0.699126  >>  [array(['Ø§Ù†Ùˆ', 'Ø¨ØªØ­Ø¨', 'Ø¬Ùˆ', 'Ø³Ø¹Ø§Ø¯', 'Ø´Ø®Øµ', 'Ø¹Ø§Ù„Ù…', 'Ø¹ÙŠØ¯', 'ÙØ±Ø­'], \n",
      "      dtype='<U22')]\n",
      "0.75  >>  0.667876  >>  [array(['Ø¨ØªÙ‡Ø¬', 'Ø³Ø®Ø±', 'Ø´ØªØºÙ„', 'Ø·Ø¨ÙŠØ¹ÙŠ', 'Ø¹Ù„ÙŠ', 'ÙƒÙÙŠ', 'Ù…Ø¹Ø§ÙŠ', 'Ù…Ùˆ'], \n",
      "      dtype='<U22')]\n",
      "0.452  >>  0.314568  >>  [array(['Ø§Ø«Ø±', 'ØªØ´ÙˆÙŠÙ‚'], \n",
      "      dtype='<U22')]\n",
      "0.172  >>  0.479073  >>  [array(['Ø§Ø­ØªÙØ§Ù„', 'Ø§Ù„Ù‡', 'Ø¯Ù†ÙŠ', 'Ø³Ø§Ù…Ø­', 'ØµÙˆØª', 'Ø·Ù„Ø¹', 'ÙØ±Øµ', 'Ù„ÙƒÙ…'], \n",
      "      dtype='<U22')]\n",
      "0.609  >>  0.60821  >>  [array(['Ø§Ø¬Ø±', 'Ø§Ù„Ù‡', 'Ø§Ù‡Ù„', 'Ø¨Ø§Ø°', 'Ø±Ø­', 'ÙØ±Ø­ÙŠ', 'Ù‚Ø¨Ù„', 'Ù‚Ø¯Ø±ÙŠ', 'ÙƒÙ…Ø§'], \n",
      "      dtype='<U22')]\n",
      "0.547  >>  0.643778  >>  [array(['Ø¬Ø¨Øª', 'ÙØ±Ø­', 'ÙØ´Ø®'], \n",
      "      dtype='<U22')]\n",
      "0.297  >>  0.514646  >>  [array(['Ø¨Ø³', 'Ø®Ø¬Ù„', 'Ø·Ø±ÙŠÙ‚', 'Ù…Ø±Ø­Ø¨', 'Ù…ÙƒÙ†'], \n",
      "      dtype='<U22')]\n",
      "0.613  >>  0.622723  >>  [array(['Ø§Ø¨ØªØ³Ø§Ù…', 'Ø§Ø«Ø±', 'Ø¬Ù…ÙŠÙ„', 'Ø­ÙˆÙ„', 'Ø¯Ø¹', 'Ø¯ÙŠÙ†', 'Ø³Ø¹Ø§Ø¯', 'ØµØ­Ù‡', 'ØµØ¯Ù‚',\n",
      "       'ÙÙ‡ÙŠ', 'Ù‚Ù„Ø¨', 'Ù„Ùƒ', 'Ù„Ù…Ù†', 'Ù…Ù„Ø§Ù…Ø­', 'Ù…ÙˆØ³ÙŠÙ‚', 'ğŸƒ'], \n",
      "      dtype='<U22')]\n",
      "0.625  >>  0.602636  >>  [array(['5050', 'Ø§Ø¹Ù„', 'Ø¨Ù‡Ø¬', 'Ø¯Ù‡', 'Ø¹Ø¨Ù‚Ø±ÙŠ'], \n",
      "      dtype='<U22')]\n",
      "0.43799999999999994  >>  0.618942  >>  [array(['Ø§Ø®Ø±', 'Ø­ÙØ¸', 'Ø±Ø¨ÙŠ', 'Ø±Ø²Ù‚', 'Ø±Ø¶Ø§', 'Ø´Ù…Ø³', 'Ø¹ØªÙ…', 'Ø¹Ù…Ø±', 'ÙØ±Ø­',\n",
      "       'ÙØ³ÙŠ', 'Ù‚Ù„Ø¨', 'Ù„Ù‡Ù…', 'Ù„ÙŠÙ„'], \n",
      "      dtype='<U22')]\n",
      "0.547  >>  0.501676  >>  [array(['Ø§ØµÙˆ', 'Ø±Ø³ÙˆÙ…', 'Ø¶Ø­Ùƒ', 'Ù…ØªØ­Ø±Ùƒ'], \n",
      "      dtype='<U22')]\n",
      "0.344  >>  0.507934  >>  [array(['Ø§Ù‡Ù„', 'Ø¨Ù„Ø§', 'Ø¬Ø§Ù…Ø¹', 'Ø­Ø¯', 'Ø³ØªÙ…ØªØ¹', 'Ø³Ø®Ø±', 'Ø´Ø¨Ø¹'], \n",
      "      dtype='<U22')]\n",
      "0.828  >>  0.721661  >>  [array(['Ø§Ù„ÙŠ', 'Ø¨ØªØ­Ù„Ù…', 'Ø¨ØªÙ†Ø§Ù…', 'Ø¨ÙŠÙ‡', 'Ø­Ø¨', 'Ø®Ù„ÙŠ', 'Ø¯Ø§', 'Ø±Ø¶ÙŠ', 'Ø³Ø¹Ø§Ø¯',\n",
      "       'ØµØ­ÙŠ', 'Ø¹Ø§Ø¯', 'ÙØ±Ø­', 'Ù‡ØªÙ„Ø§Ù‚ÙŠ'], \n",
      "      dtype='<U22')]\n",
      "0.484  >>  0.609399  >>  [array(['Ø¬Ù…Ù„', 'Ø­ÙŠØ§', 'Ø³Ø­Ø§Ø¨', 'Ø¶ØºØ·', 'Ø¹Ø´Ø§', 'ğŸ˜…'], \n",
      "      dtype='<U22')]\n",
      "0.484  >>  0.640499  >>  [array(['Ø§Ø±Ø¨', 'Ø­Ø¨', 'Ø³Ø¹Ø§Ø¯', 'Ø³Ø¹Ø¯', 'Ù‚Ù„Ø¨', 'Ù‚Ù„Ø¨ÙŠ', 'Ù…Ø³Ø§Ø¡', 'ÙŠØ§', 'âš˜'], \n",
      "      dtype='<U22')]\n",
      "0.823  >>  0.652203  >>  [array(['Ø¯ÙŠ', 'Ø³Ø®Ø±', 'Ø´ÙˆÙŠ', 'Ø·Ù„Ø¹', 'Ø¹Ù†Ø¯', 'ÙØ±Ø­', 'ÙƒØ¨Ø±', 'ÙƒÙ…Ø§', 'Ù„Ø³Ù‡'], \n",
      "      dtype='<U22')]\n",
      "0.391  >>  0.475083  >>  [array(['Ø³Ø¹Ø¯', 'Ø´ÙƒØ±', 'Ø´ÙŠØ¡', 'Ù‡Ø¯Ø§'], \n",
      "      dtype='<U22')]\n"
     ]
    }
   ],
   "source": [
    "for i in range(22,44):\n",
    "    print(y_test[-i], ' >> ', y_pred[-i], ' >> ', count_vect.inverse_transform(X_test_count[-i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
